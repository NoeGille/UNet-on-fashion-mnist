{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NoeGille/UNet-on-fashion-mnist/blob/main/UNet_on_fashion_MNIST_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpYPHZCfGCMa"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9SuWZHWFOzL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoQIMSljGGSY"
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = (28, 28, 1)\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 11\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='tmp/dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = datasets.FashionMNIST(root='tmp/dataset/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9a5UTxiUKW4L"
   },
   "outputs": [],
   "source": [
    "# A faire : ajouter des batch normalization si probl√®me de valeur extremes en sorties\n",
    "\n",
    "\n",
    "class DownSampleBlock(nn.Module):\n",
    "    '''Reduce the dimension of the image in input by 2'''\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownSampleBlock, self).__init__()\n",
    "        # We keep the same dimension in input and ouput\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
    "        self.norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
    "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
    "        self.norm2 = nn.BatchNorm2d(out_channels)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm2(self.conv2(self.relu(self.norm1(self.conv1(x)))))\n",
    "        return self.pool(x), x\n",
    "\n",
    "class DoubleConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConvolution, self).__init__()\n",
    "        # We keep the same dimension in input and ouput\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
    "        self.norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
    "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
    "        self.norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.norm2(self.conv2(self.relu(self.norm1(self.conv1(x)))))\n",
    "      return x\n",
    "\n",
    "class UpSampleBlock(nn.Module):\n",
    "    '''Increase the dimension of the input and reduce its number of channels by 2'''\n",
    "    def __init__(self, in_channels):\n",
    "        super(UpSampleBlock, self).__init__()\n",
    "        self.up1 = nn.ConvTranspose2d(in_channels, in_channels, 2, 2)\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
    "                                     out_channels=in_channels, kernel_size=(3, 3),\n",
    "                                     stride=(1, 1), padding=(1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(self.up1(x))\n",
    "        return x\n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "    '''Concatenate inputs of two blocs'''\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        '''in_channels has the same dimensions as out_channels'''\n",
    "\n",
    "        super(ResidualConnection, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels * 2, out_channels=in_channels,\n",
    "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
    "        self.norm1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
    "        self.norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.norm2(self.conv2(self.relu(self.norm1(self.conv1(x)))))\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    # Numbers of filters for the first layer of convolution\n",
    "    # <!> The number of filters will double for each down sample blocks which can\n",
    "    # lead to very high numbers of parameters very quickly <!>\n",
    "    NB_OF_FILTERS = 16\n",
    "\n",
    "    def __init__(self, input_size, num_classes:int=10, depth:int=2):\n",
    "        '''### Initialize a UNet model\n",
    "        input_size : dimension of input\n",
    "        num_classes : specify the number of classes in ouput\n",
    "        depth : the number of blocks (depth of the model)'''\n",
    "        super(UNet, self).__init__()\n",
    "        channels = [input_size[-1]] + [self.NB_OF_FILTERS * (i + 1) for i in range(depth)]\n",
    "        # first downsampling block\n",
    "        self.dblocks = nn.ModuleList([DownSampleBlock(in_channels=channels[0], out_channels=channels[1])])\n",
    "        self.bottleneck = DoubleConvolution(in_channels=channels[-1], out_channels=channels[-1])\n",
    "        # Concatenate outputs from encoder and decoder to keep tracks of objects positions\n",
    "        self.res_connect = nn.ModuleList([ResidualConnection(in_channels=channels[1], out_channels=num_classes)])\n",
    "        # Last upsampling block\n",
    "        self.ublocks = nn.ModuleList([UpSampleBlock(in_channels=channels[1])])\n",
    "\n",
    "        for i in range(1,depth):\n",
    "            # The number of channels double each time the depth increases\n",
    "            self.dblocks.append(DownSampleBlock(in_channels=channels[i], out_channels=channels[i + 1]))\n",
    "            self.res_connect.append(ResidualConnection(in_channels=channels[i + 1], out_channels=channels[i]))\n",
    "            self.ublocks.append(UpSampleBlock(in_channels=channels[i + 1]))\n",
    "        self.ublocks = self.ublocks[::-1]\n",
    "        self.res_connect = self.res_connect[::-1]\n",
    "        self.output = nn.Conv2d(in_channels=num_classes, out_channels=num_classes,\n",
    "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        depth = len(self.dblocks)\n",
    "\n",
    "        # Encoder\n",
    "        # Copy of output of each blocks before downsampling\n",
    "        xs_down =[]\n",
    "        for i, down_block in enumerate(self.dblocks):\n",
    "            x, copy = down_block.forward(x)\n",
    "            xs_down.append(copy)\n",
    "        x = self.bottleneck.forward(x)\n",
    "        xs_down = xs_down[::-1]\n",
    "        # Decoder\n",
    "        for i, up_block in enumerate(self.ublocks):\n",
    "            x_up = up_block.forward(x)\n",
    "            x = self.res_connect[i](x_up, xs_down[i])\n",
    "        \n",
    "        x = F.softmax(self.output(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0duat6UnaPdx"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = UNet(INPUT_SIZE, num_classes=NUM_CLASSES).to(device=device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8sZpi3zGt71",
    "outputId": "ad9b5cf6-9b10-4f1e-ecb6-1ad8e9b1960e"
   },
   "outputs": [],
   "source": [
    "def transform_targets(X, y_label):\n",
    "    y = np.array([cv2.threshold(img, 8, 255, type=cv2.THRESH_BINARY)[1] for img \n",
    "                  in X.permute(0, 3, 2, 1).numpy() * 255])\n",
    "    y = np.where(y == 0, 0, 1)   \n",
    "    for s in range(y.shape[0]):\n",
    "      y[s] *= y_label[s].numpy() + 1\n",
    "    return torch.from_numpy(np.eye(NUM_CLASSES, dtype='uint8')[y]).permute(0, 3, 2, 1)\n",
    "\n",
    "def metrics_values(y_valid, y_pred):\n",
    "    '''return values useful for computation of accuracy and dice score'''\n",
    "    y_valid_idx = y_valid.argmax(1)\n",
    "    y_pred_idx = y_pred.argmax(1)\n",
    "    num_correct = y_pred_idx.eq(y_valid_idx).sum().item()\n",
    "    num_samples = y_valid.size(0)\n",
    "\n",
    "    # Dice score \n",
    "    valid_mask = torch.where(y_valid_idx == 0, 0, 1).sum()\n",
    "    pred_mask = torch.where(y_pred_idx == 0, 0, 1).sum()\n",
    "    intersection = torch.where((y_valid_idx == y_pred_idx) & (y_pred_idx != 0), 1, 0).sum()\n",
    "    return (num_correct, num_samples, valid_mask, pred_mask, intersection)\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "dice_scores = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    valid_mask = 0\n",
    "    pred_mask = 0\n",
    "    intersection = 0\n",
    "    for data,y_label in tqdm(train_loader):\n",
    "        targets = transform_targets(data, y_label)\n",
    "        \n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # prediction\n",
    "        scores = model(data)\n",
    "        # Flatten the output for loss computation\n",
    "        scores = scores.permute(0, 2, 3, 1).contiguous().view(-1, scores.size(1))\n",
    "        # Flatten and convert to float targets for loss computation\n",
    "        targets = targets.permute(0, 2, 3, 1).contiguous().view(-1, targets.size(1)).float().to(device=device)\n",
    "        # Calculate loss \n",
    "        loss = criterion(scores, targets)\n",
    "        # Save data for plotting\n",
    "        values = metrics_values(targets, scores)\n",
    "        num_correct += values[0]\n",
    "        num_samples += values[1]\n",
    "        valid_mask += values[2]\n",
    "        pred_mask += values[3]\n",
    "        intersection += values[4]\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #gradient descent or adam step\n",
    "        optimizer.step()\n",
    "    acc = round(float(num_correct) / float(num_samples)*100, ndigits=2)\n",
    "    dice_score = round(2 * float(intersection) / (float(valid_mask) + float(pred_mask)), ndigits=2)\n",
    "    print(f\"accuracy {acc} and dice score {dice_score}\")\n",
    "    accuracies.append(acc)\n",
    "    dice_scores.append(dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot evolution of accuracy and dice score\n",
    "plt.plot(np.array(accuracies) / 100, label='accuracy')\n",
    "plt.plot(dice_scores, label='dice score')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHXA5TcyHbPs",
    "outputId": "0684c304-9df8-47b6-c27f-e0e4b284052b"
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on test data\")\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    intersection = 0\n",
    "    valid_mask = 0\n",
    "    pred_mask = 0\n",
    "    model.eval()\n",
    "    img = None\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for x, y in tqdm(loader):\n",
    "            y = transform_targets(x, y)\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            scores = model(x)\n",
    "\n",
    "            # Keep the first image of the batch to visualize the prediction\n",
    "            img = scores[0]\n",
    "\n",
    "            # Accuracy\n",
    "            y_valid = y.permute(0, 2, 3, 1).contiguous().view(-1, targets.size(1)).float().to(device=device)\n",
    "            y_pred = scores.permute(0, 2, 3, 1).contiguous().view(-1, scores.size(1))\n",
    "            values = metrics_values(y_valid, y_pred)\n",
    "            num_correct += values[0]\n",
    "            num_samples += values[1]\n",
    "            valid_mask += values[2]\n",
    "            pred_mask += values[3]\n",
    "            intersection += values[4]\n",
    "            \n",
    "        img = img.argmax(0).cpu().detach().numpy()\n",
    "        acc = round(float(num_correct) / float(num_samples)*100, ndigits=2)\n",
    "        dice_score = round(2 * float(intersection) / (float(valid_mask) + float(pred_mask)), ndigits=2)\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {acc} and dice score {dice_score}\")\n",
    "        \n",
    "    model.train()\n",
    "    return acc, img\n",
    "\n",
    "_, img = check_accuracy(train_loader, model)\n",
    "\n",
    "showing_result = False\n",
    "if showing_result:\n",
    "    # Showing a result (to be improved)\n",
    "    img = np.uint8(img) * 24\n",
    "    cv2.namedWindow(\"img\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('img', 600, 600)\n",
    "    cv2.imshow('img', img)\n",
    "\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vk-VlMimyT8w",
    "outputId": "2087875e-6084-4ae1-a757-a7620bdc8ddd"
   },
   "outputs": [],
   "source": [
    "check_accuracy(test_loader, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMik9nClMzaZLPOAjTGdYm0",
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
