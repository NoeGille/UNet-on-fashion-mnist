{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMik9nClMzaZLPOAjTGdYm0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoeGille/UNet-on-fashion-mnist/blob/main/UNet_on_fashion_MNIST_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "mpYPHZCfGCMa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "L9SuWZHWFOzL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SIZE = (28, 28, 1)\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_CLASSES = 10\n",
        "EPOCHS = 10\n",
        "\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='tmp/dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataset = datasets.FashionMNIST(root='tmp/dataset/', train=False, transform=transforms.ToTensor(), download=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
      ],
      "metadata": {
        "id": "qoQIMSljGGSY"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A faire : ajouter des batch normalization si probl√®me de valeur extremes en sorties\n",
        "\n",
        "\n",
        "class DownSampleBlock(nn.Module):\n",
        "    '''Reduce the dimension of the image in input by 2'''\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DownSampleBlock, self).__init__()\n",
        "        # We keep the same dimension in input and ouput\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
        "        self.norm1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
        "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
        "        self.norm2 = nn.BatchNorm2d(out_channels)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2,2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm2(self.conv2(self.relu(self.norm1(self.conv1(x)))))\n",
        "        return self.pool(x), x\n",
        "\n",
        "class DoubleConvolution(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConvolution, self).__init__()\n",
        "        # We keep the same dimension in input and ouput\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
        "        self.norm1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
        "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
        "        self.norm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.norm2(self.conv2(self.relu(self.norm1(self.conv1(x)))))\n",
        "      return x\n",
        "\n",
        "class UpSampleBlock(nn.Module):\n",
        "    '''Increase the dimension of the input and reduce its number of channels by 2'''\n",
        "    def __init__(self, in_channels):\n",
        "        super(UpSampleBlock, self).__init__()\n",
        "        self.up1 = nn.ConvTranspose2d(in_channels, in_channels, 2, 2)\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
        "                                     out_channels=in_channels, kernel_size=(3, 3),\n",
        "                                     stride=(1, 1), padding=(1,1))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(self.up1(x))\n",
        "        return x\n",
        "\n",
        "class ResidualConnection(nn.Module):\n",
        "    '''Concatenate inputs of two blocs'''\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        '''in_channels has the same dimensions as out_channels'''\n",
        "\n",
        "        super(ResidualConnection, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels * 2, out_channels=in_channels,\n",
        "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
        "        self.norm1 = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
        "        self.norm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.norm2(self.conv2(self.relu(self.norm1(self.conv1(x)))))\n",
        "        return x\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    # Numbers of filters for the first layer of convolution\n",
        "    # <!> The number of filters will double for each down sample blocks which can\n",
        "    # lead to very high numbers of parameters very quickly <!>\n",
        "    NB_OF_FILTERS = 16\n",
        "\n",
        "    def __init__(self, input_size, num_classes:int=10, depth:int=2):\n",
        "        '''### Initialize a UNet model\n",
        "        input_size : dimension of input\n",
        "        num_classes : specify the number of classes in ouput\n",
        "        depth : the number of blocks (depth of the model)'''\n",
        "        super(UNet, self).__init__()\n",
        "        channels = [input_size[-1]] + [self.NB_OF_FILTERS * (i + 1) for i in range(depth)]\n",
        "        # first downsampling block\n",
        "        self.dblocks = nn.ModuleList([DownSampleBlock(in_channels=channels[0], out_channels=channels[1])])\n",
        "        self.bottleneck = DoubleConvolution(in_channels=channels[-1], out_channels=channels[-1])\n",
        "        # Concatenate outputs from encoder and decoder to keep tracks of objects positions\n",
        "        self.res_connect = nn.ModuleList([ResidualConnection(in_channels=channels[1], out_channels=num_classes)])\n",
        "        # Last upsampling block\n",
        "        self.ublocks = nn.ModuleList([UpSampleBlock(in_channels=channels[1])])\n",
        "\n",
        "        for i in range(1,depth):\n",
        "            # The number of channels double each time the depth increases\n",
        "            self.dblocks.append(DownSampleBlock(in_channels=channels[i], out_channels=channels[i + 1]))\n",
        "            self.res_connect.append(ResidualConnection(in_channels=channels[i + 1], out_channels=channels[i]))\n",
        "            self.ublocks.append(UpSampleBlock(in_channels=channels[i + 1]))\n",
        "        self.ublocks = self.ublocks[::-1]\n",
        "        self.res_connect = self.res_connect[::-1]\n",
        "        self.output = nn.Conv2d(in_channels=num_classes, out_channels=num_classes,\n",
        "                               kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        depth = len(self.dblocks)\n",
        "\n",
        "        # Encoder\n",
        "        # Copy of output of each blocks before downsampling\n",
        "        xs_down =[]\n",
        "        for i, down_block in enumerate(self.dblocks):\n",
        "            x, copy = down_block.forward(x)\n",
        "            xs_down.append(copy)\n",
        "        x = self.bottleneck.forward(x)\n",
        "        xs_down = xs_down[::-1]\n",
        "        # Decoder\n",
        "        for i, up_block in enumerate(self.ublocks):\n",
        "            x_up = up_block.forward(x)\n",
        "            x = self.res_connect[i](x_up, xs_down[i])\n",
        "        # Flatten the output for loss computation\n",
        "        x = self.output(x)\n",
        "        x = x.permute(0, 2, 3, 1).contiguous().view(-1, x.size(1))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "9a5UTxiUKW4L"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = UNet(INPUT_SIZE).to(device=device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
      ],
      "metadata": {
        "id": "0duat6UnaPdx"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_targets(X, y_label):\n",
        "    y = np.array([cv2.threshold(img, 8, 255, type=cv2.THRESH_BINARY)[1] for img \n",
        "                  in X.permute(0, 3, 2, 1).numpy() * 255])\n",
        "    y = np.where(y == 0, 0, 1)   \n",
        "    for s in range(y.shape[0]):\n",
        "      y[s] *= y_label[s].numpy()\n",
        "    return torch.from_numpy(np.eye(NUM_CLASSES, dtype='uint8')[y]).permute(0, 3, 2, 1)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for data,y_label in tqdm(train_loader):\n",
        "        targets = transform_targets(data, y_label)\n",
        "        \n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "        # data.shape = (64, 1, 28, 28)\n",
        "        # we want (64, 28, 28, 1)\n",
        "\n",
        "        # forward \n",
        "        # prediction\n",
        "        scores = model(data)\n",
        "        # Flatten and convert to float targets for loss computation\n",
        "        targets = targets.permute(0, 2, 3, 1).contiguous().view(-1, targets.size(1)).float().to(device=device)\n",
        "        # Calculate loss \n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        #gradient descent or adam step\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "K8sZpi3zGt71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9b5cf6-9b10-4f1e-ecb6-1ad8e9b1960e"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:18<00:00, 51.49it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:19<00:00, 49.35it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:18<00:00, 52.05it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:18<00:00, 49.46it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:18<00:00, 51.51it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:18<00:00, 49.64it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:17<00:00, 52.23it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:18<00:00, 49.98it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:18<00:00, 51.68it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:18<00:00, 49.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import floor\n",
        "def check_accuracy(loader, model):\n",
        "    if loader.dataset.train:\n",
        "        print(\"Checking accuracy on training data\")\n",
        "    else:\n",
        "        print(\"Checking accuracy on test data\")\n",
        "\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(loader):\n",
        "            y = transform_targets(x, y)\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            \n",
        "            y = y.permute(0, 2, 3, 1).contiguous().view(-1, targets.size(1)).float().to(device=device)\n",
        "\n",
        "            # Accuracy\n",
        "            scores = model(x)\n",
        "            _, predictions= scores.max(1)\n",
        "            num_correct += predictions.eq(y.argmax(1)).sum().item()\n",
        "            num_samples += y.size(0)\n",
        "\n",
        "            # Dice score\n",
        "\n",
        "        acc = round(float(num_correct) / float(num_samples)*100, ndigits=2)\n",
        "        print(f\"Got {num_correct} / {num_samples} with accuracy {acc}\")\n",
        "      \n",
        "    model.train()\n",
        "    return acc\n",
        "\n",
        "check_accuracy(train_loader, model)"
      ],
      "metadata": {
        "id": "iHXA5TcyHbPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0684c304-9df8-47b6-c27f-e0e4b284052b"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking accuracy on training data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:14<00:00, 65.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 45055987 / 47040000 with accuracy 95.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95.78"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_accuracy(test_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk-VlMimyT8w",
        "outputId": "2087875e-6084-4ae1-a757-a7620bdc8ddd"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking accuracy on test data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 66.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 7411854 / 7840000 with accuracy 94.54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.54"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    }
  ]
}